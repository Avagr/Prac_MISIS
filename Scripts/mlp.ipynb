{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from data_preparation import DataExtractor\n",
    "from nn_training import train, set_random_seed\n",
    "\n",
    "run_config = {\n",
    "    'hidden_sizes': [100, 50, 50],\n",
    "    'lr': 3e-5,\n",
    "    'weight_decay': 0,\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "set_random_seed(57)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = '../Data/'\n",
    "\n",
    "extractor = DataExtractor()\n",
    "\n",
    "for base_element in ('Ti', 'Zr'):\n",
    "    files_dir = os.path.join(data_dir, base_element)\n",
    "    for file in os.listdir(files_dir):\n",
    "        if file.endswith('.dat'):\n",
    "            extractor.read_file(files_dir, file, 2, base_element)\n",
    "        elif file.endswith('.unalloyed'):\n",
    "            extractor.read_file(files_dir, file, 1, base_element)\n",
    "files_dir = os.path.join(data_dir, 'Ternary')\n",
    "for file in os.listdir(files_dir):\n",
    "    if file.endswith('.dat'):\n",
    "        extractor.read_file(files_dir, file, num_elements=3, base_element='Ti')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = extractor.dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "features = data.apply(extractor.extract_properties, axis=1, result_type='expand').to_numpy()\n",
    "target = data['a'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train_mlp(features_train, features_test, target_train, target_test):\n",
    "    scaler = StandardScaler().fit(features_train)\n",
    "    scaled_features_train = scaler.transform(features_train)\n",
    "    scaled_features_test = scaler.transform(features_test)\n",
    "    target_scaler = StandardScaler().fit(target_train.reshape(-1, 1))\n",
    "    scaled_target_train = target_scaler.transform(target_train.reshape(-1, 1))\n",
    "    scaled_target_test = target_scaler.transform(target_test.reshape(-1, 1))\n",
    "\n",
    "    train_dataset = TensorDataset(torch.Tensor(scaled_features_train), torch.Tensor(scaled_target_train))\n",
    "    test_dataset = TensorDataset(torch.Tensor(scaled_features_test), torch.Tensor(scaled_target_test))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=run_config['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=run_config['batch_size'], shuffle=False)\n",
    "\n",
    "    model = nn.Sequential(nn.Linear(5, run_config['hidden_sizes'][0]),\n",
    "                          nn.BatchNorm1d(run_config['hidden_sizes'][0]),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(run_config['hidden_sizes'][0], run_config['hidden_sizes'][1]),\n",
    "                          nn.BatchNorm1d(run_config['hidden_sizes'][1]),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(run_config['hidden_sizes'][1], run_config['hidden_sizes'][2]),\n",
    "                          nn.BatchNorm1d(run_config['hidden_sizes'][2]),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(run_config['hidden_sizes'][2], 1))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=run_config['lr'], weight_decay=run_config['weight_decay'])\n",
    "    loss = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=300, verbose=True)\n",
    "    res_train, res_test = train(model, train_loader, test_loader, test_loader, loss, optimizer, \"cuda:0\",\n",
    "                                n_epochs=3000, scheduler=scheduler, verbose=False,\n",
    "                                check_dir=None, save_every=5,\n",
    "                                model_name='nn_a', show_tqdm=False)\n",
    "    return target_scaler.inverse_transform(np.array(res_train)), target_scaler.inverse_transform(np.array(res_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01385: reducing learning rate of group 0 to 3.0000e-06.\n",
      "Epoch 01686: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 01987: reducing learning rate of group 0 to 3.0000e-08.\n",
      "Epoch 02288: reducing learning rate of group 0 to 3.0000e-09.\n",
      "A MSE Train: 0.038±0.002\n",
      "A MSE Test:  0.000±0.000\n",
      "A R^2 Train: -0.971±0.056\n",
      "A R^2 Test:  0.983±0.001\n"
     ]
    }
   ],
   "source": [
    "cv_mse_train = []\n",
    "cv_mse_test = []\n",
    "cv_r2_train = []\n",
    "cv_r2_test = []\n",
    "\n",
    "for train_index, test_index in KFold(n_splits=5, shuffle=True, random_state=57).split(features):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    target_train, target_test = target[train_index], target[test_index]\n",
    "    res_train, res_test = train_mlp(features_train, features_test, target_train, target_test)\n",
    "\n",
    "    cv_mse_train.append(mean_squared_error(target_train, res_train))\n",
    "    cv_mse_test.append(mean_squared_error(target_test, res_test))\n",
    "    cv_r2_train.append(r2_score(target_train, res_train))\n",
    "    cv_r2_test.append(r2_score(target_test, res_test))\n",
    "\n",
    "print(f\"A MSE Train: {np.mean(cv_mse_train):.3f}±{np.std(cv_mse_train):.3f}\\n\"\n",
    "      f\"A MSE Test:  {np.mean(cv_mse_test):.3f}±{np.std(cv_mse_test):.3f}\")\n",
    "print(f\"A R^2 Train: {np.mean(cv_r2_train):.3f}±{np.std(cv_r2_train):.3f}\\n\"\n",
    "      f\"A R^2 Test:  {np.mean(cv_r2_test):.3f}±{np.std(cv_r2_test):.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01826: reducing learning rate of group 0 to 3.0000e-06.\n",
      "Epoch 02127: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 02724: reducing learning rate of group 0 to 3.0000e-08.\n",
      "Epoch 02532: reducing learning rate of group 0 to 3.0000e-06.\n",
      "Epoch 02833: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 01309: reducing learning rate of group 0 to 3.0000e-06.\n",
      "Epoch 01952: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 02253: reducing learning rate of group 0 to 3.0000e-08.\n",
      "E MSE Train: 2158.031±151.071\n",
      "E MSE Test:  200.305±97.366\n",
      "E R^2 Train: -0.865±0.053\n",
      "E R^2 Test:  0.827±0.062\n"
     ]
    }
   ],
   "source": [
    "features = data.apply(extractor.extract_properties, axis=1, result_type='expand').to_numpy()\n",
    "target = data['e'].to_numpy()\n",
    "\n",
    "cv_mse_train = []\n",
    "cv_mse_test = []\n",
    "cv_r2_train = []\n",
    "cv_r2_test = []\n",
    "\n",
    "for train_index, test_index in KFold(n_splits=5, shuffle=True, random_state=57).split(features):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    target_train, target_test = target[train_index], target[test_index]\n",
    "    res_train, res_test = train_mlp(features_train, features_test, target_train, target_test)\n",
    "\n",
    "    cv_mse_train.append(mean_squared_error(target_train, res_train))\n",
    "    cv_mse_test.append(mean_squared_error(target_test, res_test))\n",
    "    cv_r2_train.append(r2_score(target_train, res_train))\n",
    "    cv_r2_test.append(r2_score(target_test, res_test))\n",
    "\n",
    "print(f\"E MSE Train: {np.mean(cv_mse_train):.3f}±{np.std(cv_mse_train):.3f}\\n\"\n",
    "      f\"E MSE Test:  {np.mean(cv_mse_test):.3f}±{np.std(cv_mse_test):.3f}\")\n",
    "print(f\"E R^2 Train: {np.mean(cv_r2_train):.3f}±{np.std(cv_r2_train):.3f}\\n\"\n",
    "      f\"E R^2 Test:  {np.mean(cv_r2_test):.3f}±{np.std(cv_r2_test):.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
